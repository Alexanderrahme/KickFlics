{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884b7444-e5de-405f-8b2a-89e3969a77fc",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34c3ab1c-20fb-4303-8ab5-6ca8f84c4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and packages\n",
    "import os\n",
    "import tfcoreml\n",
    "import coremltools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bf27c-1108-42c5-b150-67a61c19d05d",
   "metadata": {},
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71e3a576-d805-40b6-b252-8ccaeee18a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = 'C:/Users/Blake/Downloads/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f74b02ba-c59b-46e3-b415-37810f72c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store image file paths and corresponding labels\n",
    "image_filenames = []\n",
    "labels = []\n",
    "\n",
    "# Collect image file paths and labels from the dataset directory\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_dir = os.path.join(dataset_path, class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        image_filenames.append(os.path.join(class_dir, filename))\n",
    "        labels.append(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e788438-1814-4914-b610-fbd09b45a535",
   "metadata": {},
   "source": [
    "# Partitioning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c119eec-bf3b-4af3-aade-cf9f9769706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_filenames,\n",
    "    labels,\n",
    "    test_size = 0.2, # 20% of the dataset will be allocated to validating and testing (~831)\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size = 0.5, # the 20% split will be evenly partitioned into validation and testing sets (~415)\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e26f9-9fe1-4826-8e72-0b9ca630a924",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "556141e2-8e9f-487d-bacb-d050b6bc6273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3322 validated image filenames belonging to 2 classes.\n",
      "Found 415 validated image filenames belonging to 2 classes.\n",
      "Found 416 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an image data generator for data augmentation during training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255.0,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    ")\n",
    "\n",
    "# Create a training data generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'image_path': X_train, 'label': y_train}),\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical', # Classification task\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "# Create a validation data generator\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'image_path': X_val, 'label': y_val}),\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    ")\n",
    "\n",
    "# Create a test data generator\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0 / 255.0)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'image_path': X_test, 'label': y_test}),\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335df3e-60d1-4e66-946b-9d03b4bc57a3",
   "metadata": {},
   "source": [
    "# Setting Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "081a2e15-579b-420a-9c6f-b7030928de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base ResNet50 model with pre-trained weights\n",
    "base_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6880051f-ba6f-41fd-a4cf-b42f461e9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the custom classification head on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "predictions = Dense(len(os.listdir(dataset_path)), activation = 'softmax')(x)\n",
    "\n",
    "# Create the final model with the base model and custom head\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2b49feb-70db-4170-ae6e-09988441fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with an optimiser, loss function and evaluation metric\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de87d9-9274-4b3d-b058-4cb31dfdca05",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "412eb8df-8765-4e27-a85d-a9d69c0d4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 921s 9s/step - loss: 0.2138 - accuracy: 0.9642 - val_loss: 94.8836 - val_accuracy: 0.5157\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 912s 9s/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 1.2397 - val_accuracy: 0.4843\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 894s 9s/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 4.7575 - val_accuracy: 0.4843\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 896s 9s/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 2.2201 - val_accuracy: 0.5157\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 913s 9s/step - loss: 0.0302 - accuracy: 0.9931 - val_loss: 0.6940 - val_accuracy: 0.5157\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 962s 9s/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.6906 - val_accuracy: 0.5181\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 833s 8s/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.5981 - val_accuracy: 0.6313\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 815s 8s/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 2.0695 - val_accuracy: 0.4867\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 814s 8s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.2186 - val_accuracy: 0.9349\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 822s 8s/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0467 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x163880a8390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data generator and validate with the validation data generator\n",
    "model.fit(train_generator, validation_data = validation_generator, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41869b89-32bd-4171-8497-dc5a0c5c959a",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eef4752-cb72-499b-a539-c5d157c35e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 38s 3s/step - loss: 0.0210 - accuracy: 0.9976\n",
      "Test loss: 0.021004341542720795\n",
      "Test accuracy: 0.9975961446762085\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "eval_result = model.evaluate(test_generator)\n",
    "print('Test loss:', eval_result[0])\n",
    "print('Test accuracy:', eval_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f770c1-070d-415a-9d0a-49fb0910ad7e",
   "metadata": {},
   "source": [
    "# Exporting Model\n",
    "Exported the model as a .keras format so that I could save its configuration and exported it as a .mlmodel to allow for implementation within the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd71a0e-e599-42be-8b44-d1e09512ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for later use\n",
    "model.save('ResNet50.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67ed6976-2924-4416-9504-521b94fb1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for app implementation\n",
    "model.save('ResNet50.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aaefd7-b5e3-467a-bcf4-c770443c3e58",
   "metadata": {},
   "source": [
    "# Live Testing\n",
    "Since we'll probably need to demo the model after StuVac, we can use the below section to import the saved model, upload a photo of one of the shoes, preprocess the image and get the model to predict what shoe it is (provided it has been trained on it of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98cf52d3-ab16-4431-96de-6a127b98862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for independent testing\n",
    "test_model = tf.keras.models.load_model('ResNet50.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5ea34388-8afa-438e-9b9a-7497845299b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the shoe image\n",
    "shoe_path = 'C:/Users/Blake/Downloads/Live Test/Converse 1.jpg'\n",
    "\n",
    "# Preprocess the shoe image to ensure it's consistent with what the model was trained on\n",
    "shoe_image = image.load_img(shoe_path, target_size = (224, 224))\n",
    "shoe_image = image.img_to_array(shoe_image)\n",
    "shoe_image = np.expand_dims(shoe_image, axis = 0)\n",
    "shoe_image = shoe_image / 255.0\n",
    "\n",
    "# Grab the shoe models that the ML model was trained on\n",
    "shoe_labels = os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b68f9898-9672-42f9-a96b-cf68fc0e7512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "Predicted shoe: Converse Distrito 2.0 Canvas Low Sneaker\n"
     ]
    }
   ],
   "source": [
    "# Get the model's prediction\n",
    "prediction = test_model.predict(shoe_image)\n",
    "predicted_shoe = shoe_labels[np.argmax(prediction)]\n",
    "\n",
    "# Output the prediction\n",
    "print('Predicted shoe:', predicted_shoe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
